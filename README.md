# awesome
Awesome Apps and Papers of AI for Sciences


## Apps

|  Name  | Code | Function | Classification | Features | Detailed    |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | 
| [ChatPaper](https://chatpaper.com/) | [![](https://img.shields.io/github/stars/kaixindelele/ChatPaper?style=social)](https://github.com/kaixindelele/ChatPaper) | TBD | TBD | TBD | TBD |
| [学术版GPT](https://academic.chatwithpaper.org/) | [![](https://img.shields.io/github/stars/binary-husky/gpt_academic?style=social)](https://github.com/binary-husky/gpt_academic) | TBD | TBD | TBD | TBD |



## Papers

|  Title  |  Publication  | Code | Idea | Classification | Features    | Detailed    |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| [CycleResearcher: Improving Automated Research via Automated Review](https://openreview.net/forum?id=bjcsVLoHYs) | ICLR 2025 (Poster) | [![](https://img.shields.io/github/stars/zhu-minjun/Researcher?style=social)](https://github.com/zhu-minjun/Researcher) | TBD | TBD | TBD | TBD |
| [AutoSciLab: A Self-Driving Laboratory For Interpretable Scientific Discovery](https://arxiv.org/abs/2412.12347) | AAAI 2025 | TBD | TBD | TBD | TBD | TBD |
| [Assessing the Creativity of LLMs in Mathematical Problem Solving](https://arxiv.org/abs/2410.18336) | AAAI 2025 | [![](https://img.shields.io/github/stars/JunyiYe/CreativeMath?style=social)](https://github.com/JunyiYe/CreativeMath) | TBD | TBD | TBD | TBD |
| [The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://arxiv.org/abs/2408.06292) | ARXIV 2024 | [![](https://img.shields.io/github/stars/SakanaAI/AI-Scientist?style=social)](https://github.com/SakanaAI/AI-Scientist) | TBD | TBD | TBD | TBD |
| [MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents](https://arxiv.org/abs/2408.14033) | arXiv, 2024 |  [![](https://img.shields.io/github/stars/du-nlp-lab/MLR-Copilot?style=social)](https://github.com/du-nlp-lab/MLR-Copilot)  | 通过IdeaAgent和ExperimentAgent的协作，可以实现从研究思路生成到实验验证的自动化。结合现有资源和人机反馈机制，科研流程变得更加高效、灵活，提升了创新性和实验准确性 | - LLM Agents<br>- AutoML<br>- Research Automation | - 多Agent协作（Researcher、Coder、Reviewer）<br>- 自动论文选题与实验设计<br>-  多任务适用性与性能验证 |通过 LLM 代理驱动的自动化研究流程，将机器学习研究中的文献分析、假设生成、实验实现和结果验证整合为连贯的系统，显著降低研究门槛并提升效率 |
| [MLGym: A New Framework and Benchmark for Advancing AI Research Agents](https://arxiv.org/abs/2502.14499) | arXiv, 2025 |  [![](https://img.shields.io/github/stars/facebookresearch/MLGym?style=social)](https://github.com/facebookresearch/MLGym) | 一个用于评估和开发 AI 研究任务的 LLM 代理的新框架和基准 | Evaluationk<br>- Tools & Features | - 任务多样性<br>- 灵活性与扩展性<br>- Gym 接口优势 |面向科研任务，科研代理的标准化评估平台，推动Agent系统在科研中的实用化 |
| [MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation](https://arxiv.org/abs/2310.03302) | acm, 2024 |  [![](https://img.shields.io/github/stars/snap-stanford/MLAgentBench?style=social)](https://github.com/snap-stanford/MLAgentBench)  | 验证基于大语言模型（LLM）的代理能否自主完成机器学习实验全流程（如设计实验、编写代码、分析结果） | -机器学习<br>- 自然语言处理<br>- 人工智能 | -基于 ReAct 框架<br>- 支持Claude v1.0/2.1/3 Opus、GPT-4、GPT-4-turbo、Gemini Pro、Mixtral|agent通过Inspect Script Lines分析基线模型架构，尝试调整学习率（失败）、添加 Dropout（效果不佳），最终通过增加卷积层滤波器数量（从 6→32/16→64）提升准确率至 64.31%，满足 10% 提升目标 |
